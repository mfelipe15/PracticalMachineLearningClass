{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9\n",
    "\n",
    "## Naive Bayes with Yelp review text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the yelp reviews database  create a Naive Bayes model to predict the star rating for reviews\n",
    "\n",
    "Read `yelp.csv` into a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "      <th>review_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>text</th>\n",
       "      <th>type</th>\n",
       "      <th>user_id</th>\n",
       "      <th>cool</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9yKzy9PApeiPPOUJEtnvkg</td>\n",
       "      <td>2011-01-26</td>\n",
       "      <td>fWKvX83p0-ka4JS3dc6E5A</td>\n",
       "      <td>5</td>\n",
       "      <td>My wife took me here on my birthday for breakf...</td>\n",
       "      <td>review</td>\n",
       "      <td>rLtl8ZkDX5vH5nAx9C3q5Q</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ZRJwVLyzEJq1VAihDhYiow</td>\n",
       "      <td>2011-07-27</td>\n",
       "      <td>IjZ33sJrzXqU-0X6U8NwyA</td>\n",
       "      <td>5</td>\n",
       "      <td>I have no idea why some people give bad review...</td>\n",
       "      <td>review</td>\n",
       "      <td>0a2KyEL0d3Yb1V6aivbIuQ</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6oRAC4uyJCsJl1X0WZpVSA</td>\n",
       "      <td>2012-06-14</td>\n",
       "      <td>IESLBzqUCLdSzSqm0eCSxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>love the gyro plate. Rice is so good and I als...</td>\n",
       "      <td>review</td>\n",
       "      <td>0hT2KtfLiobPvh6cDC8JQg</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_1QQZuf4zZOyFCvXc0o6Vg</td>\n",
       "      <td>2010-05-27</td>\n",
       "      <td>G-WvGaISbqqaMHlNnByodA</td>\n",
       "      <td>5</td>\n",
       "      <td>Rosie, Dakota, and I LOVE Chaparral Dog Park!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>uZetl9T0NcROGOyFfughhg</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6ozycU1RpktNG2-1BroVtw</td>\n",
       "      <td>2012-01-05</td>\n",
       "      <td>1uJFq2r5QfJG_6ExMRCaGw</td>\n",
       "      <td>5</td>\n",
       "      <td>General Manager Scott Petello is a good egg!!!...</td>\n",
       "      <td>review</td>\n",
       "      <td>vYmM4KTsC8ZfQBg-j5MWkw</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id        date               review_id  stars  \\\n",
       "0  9yKzy9PApeiPPOUJEtnvkg  2011-01-26  fWKvX83p0-ka4JS3dc6E5A      5   \n",
       "1  ZRJwVLyzEJq1VAihDhYiow  2011-07-27  IjZ33sJrzXqU-0X6U8NwyA      5   \n",
       "2  6oRAC4uyJCsJl1X0WZpVSA  2012-06-14  IESLBzqUCLdSzSqm0eCSxQ      4   \n",
       "3  _1QQZuf4zZOyFCvXc0o6Vg  2010-05-27  G-WvGaISbqqaMHlNnByodA      5   \n",
       "4  6ozycU1RpktNG2-1BroVtw  2012-01-05  1uJFq2r5QfJG_6ExMRCaGw      5   \n",
       "\n",
       "                                                text    type  \\\n",
       "0  My wife took me here on my birthday for breakf...  review   \n",
       "1  I have no idea why some people give bad review...  review   \n",
       "2  love the gyro plate. Rice is so good and I als...  review   \n",
       "3  Rosie, Dakota, and I LOVE Chaparral Dog Park!!...  review   \n",
       "4  General Manager Scott Petello is a good egg!!!...  review   \n",
       "\n",
       "                  user_id  cool  useful  funny  \n",
       "0  rLtl8ZkDX5vH5nAx9C3q5Q     2       5      0  \n",
       "1  0a2KyEL0d3Yb1V6aivbIuQ     0       0      0  \n",
       "2  0hT2KtfLiobPvh6cDC8JQg     0       1      0  \n",
       "3  uZetl9T0NcROGOyFfughhg     1       2      0  \n",
       "4  vYmM4KTsC8ZfQBg-j5MWkw     0       0      0  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# access yelp.csv using a relative path\n",
    "import pandas as pd\n",
    "yelp = pd.read_csv('yelp.csv')\n",
    "yelp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new DataFrame that only contains the 5-star and 1-star reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# filter the DataFrame using an OR condition\n",
    "yelp_best_worst = yelp[(yelp.stars==5) | (yelp.stars==1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the new DataFrame into training and testing sets, using the review text as the only feature and the star rating as the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# define X and y\n",
    "X = yelp_best_worst.text\n",
    "y = yelp_best_worst.stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split into training and testing sets\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    My wife took me here on my birthday for breakf...\n",
       "1    I have no idea why some people give bad review...\n",
       "3    Rosie, Dakota, and I LOVE Chaparral Dog Park!!...\n",
       "4    General Manager Scott Petello is a good egg!!!...\n",
       "6    Drop what you're doing and drive here. After I...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    5\n",
       "3    5\n",
       "4    5\n",
       "6    5\n",
       "Name: stars, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.1\n",
    "\n",
    "Use CountVectorizer to create document-term matrices from X_train and X_test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3064,)\n",
      "(1022,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['00',\n",
       " '000',\n",
       " '00a',\n",
       " '00am',\n",
       " '00pm',\n",
       " '01',\n",
       " '02',\n",
       " '03',\n",
       " '03342',\n",
       " '04',\n",
       " '05',\n",
       " '06',\n",
       " '07',\n",
       " '09',\n",
       " '0buxoc0crqjpvkezo3bqog',\n",
       " '0l',\n",
       " '10',\n",
       " '100',\n",
       " '1000',\n",
       " '1000x',\n",
       " '1001',\n",
       " '100th',\n",
       " '101',\n",
       " '102',\n",
       " '105',\n",
       " '1070',\n",
       " '108',\n",
       " '10am',\n",
       " '10ish',\n",
       " '10min',\n",
       " '10mins',\n",
       " '10minutes',\n",
       " '10pm',\n",
       " '10th',\n",
       " '10x',\n",
       " '11',\n",
       " '110',\n",
       " '1100',\n",
       " '111',\n",
       " '111th',\n",
       " '112',\n",
       " '115th',\n",
       " '118',\n",
       " '11a',\n",
       " '11am',\n",
       " '11p',\n",
       " '11pm',\n",
       " '12',\n",
       " '120',\n",
       " '128i',\n",
       " '129',\n",
       " '12am',\n",
       " '12oz',\n",
       " '12pm',\n",
       " '12th',\n",
       " '13',\n",
       " '14',\n",
       " '140',\n",
       " '147',\n",
       " '14lbs',\n",
       " '15',\n",
       " '150',\n",
       " '1500',\n",
       " '150mm',\n",
       " '15am',\n",
       " '15mins',\n",
       " '15pm',\n",
       " '15th',\n",
       " '16',\n",
       " '160',\n",
       " '165',\n",
       " '169',\n",
       " '16th',\n",
       " '17',\n",
       " '17p',\n",
       " '18',\n",
       " '180',\n",
       " '18th',\n",
       " '19',\n",
       " '1900',\n",
       " '1913',\n",
       " '1928',\n",
       " '1929',\n",
       " '1930s',\n",
       " '1940',\n",
       " '1952',\n",
       " '1955',\n",
       " '1956',\n",
       " '1960',\n",
       " '1961',\n",
       " '1969',\n",
       " '1970',\n",
       " '1980',\n",
       " '1980s',\n",
       " '1987',\n",
       " '1990s',\n",
       " '1992',\n",
       " '1995',\n",
       " '1996',\n",
       " '1998',\n",
       " '1999',\n",
       " '19th',\n",
       " '1cent',\n",
       " '1k',\n",
       " '1p',\n",
       " '1pm',\n",
       " '1st',\n",
       " '20',\n",
       " '200',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '200lbs',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '202',\n",
       " '20mbs',\n",
       " '20miles',\n",
       " '20min',\n",
       " '20pm',\n",
       " '20s',\n",
       " '20th',\n",
       " '20x',\n",
       " '21',\n",
       " '22',\n",
       " '220',\n",
       " '2240',\n",
       " '22oz',\n",
       " '23',\n",
       " '24',\n",
       " '24hrs',\n",
       " '24st',\n",
       " '24th',\n",
       " '25',\n",
       " '250',\n",
       " '25b',\n",
       " '25min',\n",
       " '25th',\n",
       " '26',\n",
       " '260',\n",
       " '2600',\n",
       " '2608',\n",
       " '2669',\n",
       " '26th',\n",
       " '27',\n",
       " '272',\n",
       " '28',\n",
       " '29',\n",
       " '29th',\n",
       " '2am',\n",
       " '2mbps',\n",
       " '2nd',\n",
       " '2pm',\n",
       " '2rd',\n",
       " '2wice',\n",
       " '2x',\n",
       " '30',\n",
       " '300',\n",
       " '3000',\n",
       " '30am',\n",
       " '30p',\n",
       " '30pm',\n",
       " '30th',\n",
       " '31',\n",
       " '311',\n",
       " '312',\n",
       " '32',\n",
       " '33',\n",
       " '33rd',\n",
       " '34',\n",
       " '34th',\n",
       " '35',\n",
       " '350ib',\n",
       " '35c',\n",
       " '35th',\n",
       " '36',\n",
       " '37',\n",
       " '370',\n",
       " '38',\n",
       " '38th',\n",
       " '39',\n",
       " '3am',\n",
       " '3d',\n",
       " '3g',\n",
       " '3k',\n",
       " '3lbs',\n",
       " '3n9u549zse8up',\n",
       " '3p',\n",
       " '3pm',\n",
       " '3rd',\n",
       " '3x',\n",
       " '40',\n",
       " '400',\n",
       " '4000',\n",
       " '40lm',\n",
       " '40min',\n",
       " '40th',\n",
       " '41',\n",
       " '411',\n",
       " '4113416766',\n",
       " '42',\n",
       " '420',\n",
       " '43',\n",
       " '44',\n",
       " '4458',\n",
       " '44th',\n",
       " '45',\n",
       " '453990',\n",
       " '45min',\n",
       " '45pm',\n",
       " '46',\n",
       " '475',\n",
       " '48',\n",
       " '480',\n",
       " '48th',\n",
       " '49',\n",
       " '490',\n",
       " '4b',\n",
       " '4hr',\n",
       " '4pm',\n",
       " '4th',\n",
       " '50',\n",
       " '500',\n",
       " '50cents',\n",
       " '50lm',\n",
       " '50s',\n",
       " '51',\n",
       " '51pm',\n",
       " '52',\n",
       " '5231',\n",
       " '53',\n",
       " '53pm',\n",
       " '54',\n",
       " '55',\n",
       " '56',\n",
       " '57',\n",
       " '59',\n",
       " '59th',\n",
       " '5k',\n",
       " '5min',\n",
       " '5p',\n",
       " '5pm',\n",
       " '5stars',\n",
       " '5th',\n",
       " '60',\n",
       " '600',\n",
       " '602',\n",
       " '61',\n",
       " '61st',\n",
       " '62010',\n",
       " '623',\n",
       " '63',\n",
       " '64',\n",
       " '64th',\n",
       " '65',\n",
       " '66',\n",
       " '67',\n",
       " '68',\n",
       " '680',\n",
       " '69',\n",
       " '6am',\n",
       " '6p',\n",
       " '6pm',\n",
       " '6th',\n",
       " '70',\n",
       " '700',\n",
       " '70s',\n",
       " '70th',\n",
       " '71',\n",
       " '71st',\n",
       " '75',\n",
       " '750',\n",
       " '755891987',\n",
       " '76',\n",
       " '79',\n",
       " '7am',\n",
       " '7pm',\n",
       " '7th',\n",
       " '80',\n",
       " '800',\n",
       " '8000hp',\n",
       " '80s',\n",
       " '81',\n",
       " '83',\n",
       " '832',\n",
       " '83rd',\n",
       " '85',\n",
       " '85154658',\n",
       " '86',\n",
       " '88',\n",
       " '89',\n",
       " '8am',\n",
       " '8pm',\n",
       " '8th',\n",
       " '8v',\n",
       " '8yo',\n",
       " '90',\n",
       " '90s',\n",
       " '91',\n",
       " '911',\n",
       " '945am',\n",
       " '95',\n",
       " '96',\n",
       " '977',\n",
       " '98',\n",
       " '99',\n",
       " '9999',\n",
       " '99cent',\n",
       " '9oz',\n",
       " '9p',\n",
       " '9pm',\n",
       " '9year',\n",
       " '9yo',\n",
       " '______',\n",
       " '_______________',\n",
       " '_c',\n",
       " '_gyib8ea4hdfylss17zc_g',\n",
       " 'a1',\n",
       " 'aa',\n",
       " 'aaa',\n",
       " 'aaaamazing',\n",
       " 'aaammmazzing',\n",
       " 'aaron',\n",
       " 'ab',\n",
       " 'abandoned',\n",
       " 'abandoning',\n",
       " 'abba',\n",
       " 'abbreviate',\n",
       " 'abbreviated',\n",
       " 'abby',\n",
       " 'abc',\n",
       " 'abdomen',\n",
       " 'abilities',\n",
       " 'ability',\n",
       " 'able',\n",
       " 'abodoba',\n",
       " 'abound',\n",
       " 'about',\n",
       " 'above',\n",
       " 'abrasion',\n",
       " 'abroad',\n",
       " 'abrupt',\n",
       " 'absent',\n",
       " 'absinthe',\n",
       " 'absoloutely',\n",
       " 'absolut',\n",
       " 'absolute',\n",
       " 'absolutely',\n",
       " 'absolutley',\n",
       " 'absolutly',\n",
       " 'abstained',\n",
       " 'absurd',\n",
       " 'abuelo',\n",
       " 'abundance',\n",
       " 'abundant',\n",
       " 'abuse',\n",
       " 'abused',\n",
       " 'abusive',\n",
       " 'ac',\n",
       " 'academy',\n",
       " 'acapulco',\n",
       " 'accent',\n",
       " 'accented',\n",
       " 'accents',\n",
       " 'accept',\n",
       " 'acceptable',\n",
       " 'accepted',\n",
       " 'access',\n",
       " 'accessed',\n",
       " 'accessible',\n",
       " 'accessories',\n",
       " 'accessorize',\n",
       " 'accessory',\n",
       " 'accident',\n",
       " 'accidental',\n",
       " 'accidentally',\n",
       " 'accolades',\n",
       " 'accommodate',\n",
       " 'accommodated',\n",
       " 'accommodates',\n",
       " 'accommodating',\n",
       " 'accommodations',\n",
       " 'accomodate',\n",
       " 'accomodating',\n",
       " 'accompanied',\n",
       " 'accompanies',\n",
       " 'accompaniment',\n",
       " 'accompany',\n",
       " 'accompanying',\n",
       " 'accomplish',\n",
       " 'accomplished',\n",
       " 'accomplishment',\n",
       " 'according',\n",
       " 'accordingly',\n",
       " 'account',\n",
       " 'accounts',\n",
       " 'accoutrement',\n",
       " 'accredited',\n",
       " 'accross',\n",
       " 'accurate',\n",
       " 'accurately',\n",
       " 'accusation',\n",
       " 'accustom',\n",
       " 'accustomed',\n",
       " 'accutemp',\n",
       " 'ace',\n",
       " 'ache',\n",
       " 'aches',\n",
       " 'achieve',\n",
       " 'achievement',\n",
       " 'acid',\n",
       " 'acidic',\n",
       " 'acknowledge',\n",
       " 'acknowledged',\n",
       " 'acknowledgement',\n",
       " 'acknowledging',\n",
       " 'ackward',\n",
       " 'acne',\n",
       " 'acoustic',\n",
       " 'acoustics',\n",
       " 'acquaintance',\n",
       " 'acres',\n",
       " 'acrid',\n",
       " 'acrimonious',\n",
       " 'across',\n",
       " 'acrylics',\n",
       " 'act',\n",
       " 'acted',\n",
       " 'acting',\n",
       " 'action',\n",
       " 'actions',\n",
       " 'activation',\n",
       " 'active',\n",
       " 'actively',\n",
       " 'activism',\n",
       " 'activities',\n",
       " 'activity',\n",
       " 'actor',\n",
       " 'actors',\n",
       " 'acts',\n",
       " 'actual',\n",
       " 'actually',\n",
       " 'actualy',\n",
       " 'actully',\n",
       " 'acute',\n",
       " 'acy',\n",
       " 'ad',\n",
       " 'adage',\n",
       " 'adam',\n",
       " 'adamant',\n",
       " 'adams',\n",
       " 'adapter',\n",
       " 'add',\n",
       " 'added',\n",
       " 'addendum',\n",
       " 'addict',\n",
       " 'addicted',\n",
       " 'addicting',\n",
       " 'addictingly',\n",
       " 'addiction',\n",
       " 'addictionovercome',\n",
       " 'addictive',\n",
       " 'addicts',\n",
       " 'adding',\n",
       " 'addition',\n",
       " 'additional',\n",
       " 'additionally',\n",
       " 'additions',\n",
       " 'address',\n",
       " 'addressed',\n",
       " 'addressing',\n",
       " 'adds',\n",
       " 'ade',\n",
       " 'adelman',\n",
       " 'adequate',\n",
       " 'adequately',\n",
       " 'adios',\n",
       " 'adjacent',\n",
       " 'adjoining',\n",
       " 'adjust',\n",
       " 'adjusted',\n",
       " 'adjustment',\n",
       " 'adjustments',\n",
       " 'administrative',\n",
       " 'admire',\n",
       " 'admission',\n",
       " 'admit',\n",
       " 'admits',\n",
       " 'admitted',\n",
       " 'admittedly',\n",
       " 'admitting',\n",
       " 'admonishment',\n",
       " 'adobada',\n",
       " 'adobe',\n",
       " 'adobo',\n",
       " 'adolescence',\n",
       " 'adopt',\n",
       " 'adopted',\n",
       " 'adoption',\n",
       " 'adoptions',\n",
       " 'adorable',\n",
       " 'adore',\n",
       " 'adorning',\n",
       " 'adovada',\n",
       " 'adquate',\n",
       " 'adrienne',\n",
       " 'ads',\n",
       " 'adult',\n",
       " 'adulthood',\n",
       " 'adults',\n",
       " 'advance',\n",
       " 'advanced',\n",
       " 'advancing',\n",
       " 'advantage',\n",
       " 'advantages',\n",
       " 'adventure',\n",
       " 'adventures',\n",
       " 'adventurous',\n",
       " 'adverse',\n",
       " 'adversity',\n",
       " 'advertise',\n",
       " 'advertised',\n",
       " 'advertisement',\n",
       " 'advertising',\n",
       " 'adverts',\n",
       " 'advice',\n",
       " 'advise',\n",
       " 'advised',\n",
       " 'advising',\n",
       " 'advisor',\n",
       " 'advocate',\n",
       " 'advocated',\n",
       " 'aeg',\n",
       " 'aerators',\n",
       " 'aerobic',\n",
       " 'aerobics',\n",
       " 'aeropress',\n",
       " 'aesthetically',\n",
       " 'aesthetics',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'affected',\n",
       " 'affects',\n",
       " 'afficianados',\n",
       " 'affiliated',\n",
       " 'affiliation',\n",
       " 'affluent',\n",
       " 'afforadable',\n",
       " 'afford',\n",
       " 'affordable',\n",
       " 'aficionado',\n",
       " 'aficionados',\n",
       " 'afloat',\n",
       " 'aforementioned',\n",
       " 'afoul',\n",
       " 'afraid',\n",
       " 'africa',\n",
       " 'after',\n",
       " 'afterall',\n",
       " 'afterdark',\n",
       " 'afterglow',\n",
       " 'afternoon',\n",
       " 'afternoons',\n",
       " 'aftertaste',\n",
       " 'afterthought',\n",
       " 'afterward',\n",
       " 'afterwards',\n",
       " 'again',\n",
       " 'against',\n",
       " 'agape',\n",
       " 'agave',\n",
       " 'agaves',\n",
       " 'age',\n",
       " 'aged',\n",
       " 'agency',\n",
       " 'agent',\n",
       " 'agents',\n",
       " 'ages',\n",
       " 'aggressive',\n",
       " 'aging',\n",
       " 'agitated',\n",
       " 'ago',\n",
       " 'agonizing',\n",
       " 'agree',\n",
       " 'agreeable',\n",
       " 'agreed',\n",
       " 'agreeing',\n",
       " 'agreement',\n",
       " 'agrees',\n",
       " 'agua',\n",
       " 'aguas',\n",
       " 'agwa',\n",
       " 'ah',\n",
       " 'ahead',\n",
       " 'ahem',\n",
       " 'ahh',\n",
       " 'ahhh',\n",
       " 'ahhhh',\n",
       " 'ahhhhh',\n",
       " 'ahi',\n",
       " 'ahold',\n",
       " 'ahwatukee',\n",
       " 'aid',\n",
       " 'aiello',\n",
       " 'aiko',\n",
       " 'aim',\n",
       " 'aimed',\n",
       " 'aimlessly',\n",
       " 'aims',\n",
       " 'ain',\n",
       " 'aint',\n",
       " 'aioli',\n",
       " 'aiptasia',\n",
       " 'air',\n",
       " 'airconditioned',\n",
       " 'airfair',\n",
       " 'airfare',\n",
       " 'airline',\n",
       " 'airlines',\n",
       " 'airpark',\n",
       " 'airplane',\n",
       " 'airport',\n",
       " 'airports',\n",
       " 'airwarys',\n",
       " 'airways',\n",
       " 'airy',\n",
       " 'aisha',\n",
       " 'aisle',\n",
       " 'aisles',\n",
       " 'aj',\n",
       " 'aji',\n",
       " 'ajo',\n",
       " 'ajos',\n",
       " 'ajs',\n",
       " 'ajvar',\n",
       " 'aka',\n",
       " 'aki',\n",
       " 'aknowledging',\n",
       " 'akor',\n",
       " 'al',\n",
       " 'ala',\n",
       " 'alabama',\n",
       " 'alain',\n",
       " 'alameda',\n",
       " 'alan',\n",
       " 'alarmed',\n",
       " 'alas',\n",
       " 'alaskan',\n",
       " 'alaus',\n",
       " 'albacore',\n",
       " 'albeit',\n",
       " 'alber',\n",
       " 'album',\n",
       " 'albums',\n",
       " 'alcohol',\n",
       " 'alcoholic',\n",
       " 'aldo',\n",
       " 'ale',\n",
       " 'alert',\n",
       " 'alex',\n",
       " 'alexandra',\n",
       " 'alfalfa',\n",
       " 'alfonso',\n",
       " 'alfred',\n",
       " 'alfredo',\n",
       " 'algae',\n",
       " 'ali',\n",
       " 'alice',\n",
       " 'alicia',\n",
       " 'aliens',\n",
       " 'alike',\n",
       " 'alittle',\n",
       " 'alive',\n",
       " 'all',\n",
       " 'alla',\n",
       " 'allayed',\n",
       " 'alleged',\n",
       " 'allegiant',\n",
       " 'allen',\n",
       " 'allende',\n",
       " 'allergen',\n",
       " 'allergic',\n",
       " 'allergies',\n",
       " 'allergy',\n",
       " 'alleviated',\n",
       " 'alley',\n",
       " 'alligator',\n",
       " 'allocating',\n",
       " 'allot',\n",
       " 'alloted',\n",
       " 'allotted',\n",
       " 'allow',\n",
       " 'allowable',\n",
       " 'allowance',\n",
       " 'allowed',\n",
       " 'allowing',\n",
       " 'allows',\n",
       " 'allure',\n",
       " 'almond',\n",
       " 'almonds',\n",
       " 'almost',\n",
       " 'aloe',\n",
       " 'alofts',\n",
       " 'aloha',\n",
       " 'alone',\n",
       " 'along',\n",
       " 'alongside',\n",
       " 'alons',\n",
       " 'aloo',\n",
       " 'aloof',\n",
       " 'alot',\n",
       " 'aloud',\n",
       " 'alp',\n",
       " 'already',\n",
       " 'alright',\n",
       " 'also',\n",
       " 'alteration',\n",
       " 'alterations',\n",
       " 'altercation',\n",
       " 'altered',\n",
       " 'altering',\n",
       " 'alternately',\n",
       " 'alternative',\n",
       " 'alternatively',\n",
       " 'alternatives',\n",
       " 'although',\n",
       " 'altic',\n",
       " 'aluminum',\n",
       " 'alway',\n",
       " 'always',\n",
       " 'am',\n",
       " 'ama',\n",
       " 'amaaaaazing',\n",
       " 'amaazing',\n",
       " 'amados',\n",
       " 'amalfi',\n",
       " 'amanda',\n",
       " 'amaretti',\n",
       " 'amaretto',\n",
       " 'amarillo',\n",
       " 'amaro',\n",
       " 'amateur',\n",
       " 'amaze',\n",
       " 'amazed',\n",
       " 'amazement',\n",
       " 'amazes',\n",
       " 'amazing',\n",
       " 'amazingly',\n",
       " 'amazingness',\n",
       " 'amazon',\n",
       " 'amazzzzzzing',\n",
       " 'ambassador',\n",
       " 'amber',\n",
       " 'ambiance',\n",
       " 'ambience',\n",
       " 'ambient',\n",
       " 'ambrosia',\n",
       " 'amc',\n",
       " 'amenable',\n",
       " 'amendment',\n",
       " 'amenities',\n",
       " 'america',\n",
       " 'american',\n",
       " 'americana',\n",
       " 'americanized',\n",
       " 'americano',\n",
       " 'americanos',\n",
       " 'americans',\n",
       " 'ami',\n",
       " 'amicable',\n",
       " 'amidst',\n",
       " 'amin',\n",
       " 'amish',\n",
       " 'ammo',\n",
       " 'amomi',\n",
       " 'among',\n",
       " 'amongst',\n",
       " 'amore',\n",
       " 'amount',\n",
       " 'amounted',\n",
       " 'amounts',\n",
       " 'amp',\n",
       " 'amphitheatre',\n",
       " 'ample',\n",
       " 'ampm',\n",
       " 'amtrack',\n",
       " 'amuse',\n",
       " 'amused',\n",
       " 'amusement',\n",
       " 'amusing',\n",
       " 'amy',\n",
       " 'an',\n",
       " 'anal',\n",
       " 'analysis',\n",
       " 'ancho',\n",
       " 'anchor',\n",
       " 'anchors',\n",
       " 'anchovies',\n",
       " 'anchovy',\n",
       " 'and',\n",
       " 'andiamo',\n",
       " 'andouille',\n",
       " 'andrea',\n",
       " 'andrew',\n",
       " 'andy',\n",
       " 'anecdotes',\n",
       " 'anemic',\n",
       " 'anesthetic',\n",
       " 'anew',\n",
       " 'angel',\n",
       " 'angela',\n",
       " 'angeles',\n",
       " 'angelic',\n",
       " 'angello',\n",
       " 'angels',\n",
       " 'anger',\n",
       " 'anglaise',\n",
       " 'angle',\n",
       " 'angler',\n",
       " 'angles',\n",
       " 'angry',\n",
       " 'angst',\n",
       " 'anibal',\n",
       " 'animal',\n",
       " 'animals',\n",
       " 'animated',\n",
       " 'animatronics',\n",
       " 'anise',\n",
       " 'aniston',\n",
       " 'ankle',\n",
       " 'ankles',\n",
       " 'ann',\n",
       " 'anne',\n",
       " 'annie',\n",
       " 'annihilator',\n",
       " 'anniversary',\n",
       " 'announced',\n",
       " 'annoy',\n",
       " 'annoyance',\n",
       " 'annoyed',\n",
       " 'annoying',\n",
       " 'annual',\n",
       " 'anomaly',\n",
       " 'anonymous',\n",
       " 'another',\n",
       " 'ans',\n",
       " 'ansel',\n",
       " 'answer',\n",
       " 'answered',\n",
       " 'answering',\n",
       " 'answers',\n",
       " 'ant',\n",
       " 'anthem',\n",
       " 'anthony',\n",
       " 'anti',\n",
       " 'anticipate',\n",
       " 'anticipated',\n",
       " 'anticipating',\n",
       " 'anticipation',\n",
       " 'antipasti',\n",
       " 'antipasto',\n",
       " 'antique',\n",
       " 'antiques',\n",
       " 'antiquing',\n",
       " 'antiseptic',\n",
       " 'antithesis',\n",
       " 'antler',\n",
       " 'antonio',\n",
       " 'antono',\n",
       " 'ants',\n",
       " 'anxiety',\n",
       " 'anxious',\n",
       " 'anxiously',\n",
       " 'any',\n",
       " 'anybody',\n",
       " 'anyday',\n",
       " 'anyhoo',\n",
       " 'anyhow',\n",
       " 'anymore',\n",
       " 'anyone',\n",
       " 'anyplace',\n",
       " 'anything',\n",
       " 'anythings',\n",
       " 'anytime',\n",
       " 'anyway',\n",
       " 'anyways',\n",
       " 'anywhere',\n",
       " 'anywho',\n",
       " 'ao',\n",
       " 'ap',\n",
       " 'apache',\n",
       " 'apart',\n",
       " 'apartment',\n",
       " 'apartments',\n",
       " 'ape',\n",
       " 'apiece',\n",
       " 'apologetic',\n",
       " 'apologetically',\n",
       " 'apologists',\n",
       " 'apologize',\n",
       " 'apologized',\n",
       " 'apologizes',\n",
       " 'apologizing',\n",
       " 'apology',\n",
       " 'apostles',\n",
       " 'apothecary',\n",
       " 'apothic',\n",
       " 'app',\n",
       " 'appalachians',\n",
       " 'appaled',\n",
       " 'appalled',\n",
       " 'appalling',\n",
       " 'apparantly',\n",
       " 'apparel',\n",
       " 'apparent',\n",
       " 'apparently',\n",
       " 'appauling',\n",
       " 'appeal',\n",
       " 'appealed',\n",
       " 'appealing',\n",
       " 'appeals',\n",
       " 'appear',\n",
       " 'appearance',\n",
       " 'appearances',\n",
       " 'appeared',\n",
       " 'appears',\n",
       " 'appeasing',\n",
       " 'appertizer',\n",
       " 'appetit',\n",
       " 'appetite',\n",
       " 'appetito',\n",
       " 'appetizaer',\n",
       " 'appetizer',\n",
       " 'appetizers',\n",
       " 'appetizing',\n",
       " 'applaud',\n",
       " 'apple',\n",
       " 'applebee',\n",
       " 'applebees',\n",
       " 'apples',\n",
       " 'appletini',\n",
       " 'appletinis',\n",
       " 'appliances',\n",
       " 'applied',\n",
       " 'applies',\n",
       " 'apply',\n",
       " 'applying',\n",
       " 'appoinmtnt',\n",
       " 'appointed',\n",
       " 'appointment',\n",
       " 'appointments',\n",
       " 'appologized',\n",
       " 'appraisal',\n",
       " 'appraisals',\n",
       " 'appraiser',\n",
       " 'appreciate',\n",
       " 'appreciated',\n",
       " 'appreciates',\n",
       " 'appreciation',\n",
       " 'appreciative',\n",
       " 'apprehensive',\n",
       " 'appreicate',\n",
       " 'approach',\n",
       " 'approachable',\n",
       " 'approached',\n",
       " 'approaches',\n",
       " 'approaching',\n",
       " 'appropriate',\n",
       " 'appropriately',\n",
       " 'approx',\n",
       " 'approximate',\n",
       " 'approximately',\n",
       " 'apps',\n",
       " 'appt',\n",
       " 'appys',\n",
       " 'apricot',\n",
       " 'april',\n",
       " 'apron',\n",
       " 'apt',\n",
       " 'aqua',\n",
       " 'aquarium',\n",
       " 'aquiring',\n",
       " 'ar',\n",
       " 'arabic',\n",
       " 'arai',\n",
       " 'arbol',\n",
       " 'arboreal',\n",
       " 'arborio',\n",
       " 'arcade',\n",
       " 'arcadia',\n",
       " 'arcane',\n",
       " 'arches',\n",
       " 'architect',\n",
       " 'architecture',\n",
       " ...]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer()\n",
    "vect.fit(X_train)\n",
    "vect.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3064, 16825)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect.fit(X_train)\n",
    "X_train_dtm = vect.transform(X_train)\n",
    "X_train_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1022, 16825)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ..., \n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_dtm.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>00a</th>\n",
       "      <th>00am</th>\n",
       "      <th>00pm</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>03342</th>\n",
       "      <th>04</th>\n",
       "      <th>...</th>\n",
       "      <th>zucchini</th>\n",
       "      <th>zuchinni</th>\n",
       "      <th>zumba</th>\n",
       "      <th>zupa</th>\n",
       "      <th>zuzu</th>\n",
       "      <th>zwiebel</th>\n",
       "      <th>zzed</th>\n",
       "      <th>éclairs</th>\n",
       "      <th>école</th>\n",
       "      <th>ém</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16825 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  00a  00am  00pm  01  02  03  03342  04 ...  zucchini  zuchinni  \\\n",
       "0   0    0    0     0     0   0   0   0      0   0 ...         0         0   \n",
       "1   0    0    0     0     0   0   0   0      0   0 ...         0         0   \n",
       "2   0    0    0     0     0   0   0   0      0   0 ...         0         0   \n",
       "3   0    0    0     0     0   0   0   0      0   0 ...         0         0   \n",
       "4   0    0    0     0     0   0   0   0      0   0 ...         0         0   \n",
       "\n",
       "   zumba  zupa  zuzu  zwiebel  zzed  éclairs  école  ém  \n",
       "0      0     0     0        0     0        0      0   0  \n",
       "1      0     0     0        0     0        0      0   0  \n",
       "2      0     0     0        0     0        0      0   0  \n",
       "3      0     0     0        0     0        0      0   0  \n",
       "4      0     0     0        0     0        0      0   0  \n",
       "\n",
       "[5 rows x 16825 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_train_dtm.toarray(), columns=vect.get_feature_names()).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.2\n",
    "\n",
    "Use Naive Bayes to predict the star rating for reviews in the testing set, and calculate the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "nb.fit(X_train_dtm, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred_class = nb.predict(X_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.918786692759\n"
     ]
    }
   ],
   "source": [
    "# calculate accuracy of class predictions\n",
    "from sklearn import metrics\n",
    "print(metrics.accuracy_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.3\n",
    "\n",
    "Calculate the AUC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  1.00000000e+00,   9.99759874e-01,   1.00000000e+00, ...,\n",
       "         1.00000000e+00,   1.05200807e-19,   9.99915316e-01])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict (poorly calibrated) probabilities\n",
    "y_pred_prob = nb.predict_proba(X_test_dtm)[:, 1]\n",
    "y_pred_prob\n",
    "# calculate AUC\n",
    "#print(metrics.roc_auc_score(y_test, y_pred_prob))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.4\n",
    "\n",
    "Print the confusion matrix.\n",
    "\n",
    "Calculate the Precesion, Recall and F1Score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[126  58]\n",
      " [ 25 813]]\n"
     ]
    }
   ],
   "source": [
    "print(metrics.confusion_matrix(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score  0.834437086093\n",
      "recall_score     0.684782608696\n",
      "f1_score     0.75223880597\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "print('precision_score ', precision_score(y_test, y_pred_class))\n",
    "print('recall_score    ', recall_score(y_test, y_pred_class))\n",
    "print('f1_score    ', f1_score(y_test, y_pred_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 9.5\n",
    "\n",
    "Browse through the review text for some of the false positives and false negatives. Based on your knowledge of how Naive Bayes works, do you have any theories about why the model is incorrectly classifying these reviews?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2175    This has to be the worst restaurant in terms o...\n",
       "1781    If you like the stuck up Scottsdale vibe this ...\n",
       "2674    I'm sorry to be what seems to be the lone one ...\n",
       "9984    Went last night to Whore Foods to get basics t...\n",
       "3392    I found Lisa G's while driving through phoenix...\n",
       "8283    Don't know where I should start. Grand opening...\n",
       "2765    Went last week, and ordered a dozen variety. I...\n",
       "2839    Never Again,\\nI brought my Mountain Bike in (w...\n",
       "321     My wife and I live around the corner, hadn't e...\n",
       "1919                                         D-scust-ing.\n",
       "2490    Lazy Q CLOSED in 2010.  New Owners cleaned up ...\n",
       "9125    La Grande Orange Grocery has a problem. It can...\n",
       "9185    For frozen yogurt quality, I give this place a...\n",
       "436     this another place that i would give no stars ...\n",
       "2051    Sadly with new owners comes changes on menu.  ...\n",
       "1721    This is the closest to a New York hipster styl...\n",
       "3447    If you want a school that cares more about you...\n",
       "842     Boy is the name a temptation.Seriously :)  I'l...\n",
       "6159    Really, if I could, I would give this place ze...\n",
       "943     Don't waste your time...Arrowhead mall on the ...\n",
       "5977    You want good food? You'd be better off smuggl...\n",
       "8833    The owner has changed hands & this place isn't...\n",
       "6584    Jimmy Johns is cheaper and better ... The Capr...\n",
       "1899    Buca Di Beppo is literally, italian restaurant...\n",
       "9953    \"Hipster,Trendy\" ????-I think NOT !!!! Very di...\n",
       "2060                This place is closed.  Good riddance.\n",
       "3082    Currently having a liquidation sale, but it's ...\n",
       "8220    Maybe I ate at a different restaurant than the...\n",
       "3634    Seriously?! With grocery stores like Fresh & E...\n",
       "3266    Absolutely awful... these guys have NO idea wh...\n",
       "7397    This place sucks!! I moved to the valley and h...\n",
       "4473    It is what you would expect from any themed pl...\n",
       "5502    Angry Bro Bar !  Please go here if you wear si...\n",
       "2615    Great in its day, now leaves a lot to be desir...\n",
       "3413    I purchased the Enotria groupon when it was re...\n",
       "2999    I can't even believe I actually went to this r...\n",
       "1372    No offense to everyone who gave this place 5 s...\n",
       "1291    Every time I come here the staff is so rude! I...\n",
       "6222    My mother always told me, if I didn't have any...\n",
       "9296    My boyfriend and I tried this place last year ...\n",
       "7975    What are you all talking about?! This place is...\n",
       "4630    I used to always go here for tires until my me...\n",
       "7130    I was not impressed. The food was bad & expens...\n",
       "5818    Most horrible buffet I have ever been to.\\n\\nM...\n",
       "3704    Staff is nice, and that's it.\\nThey use very c...\n",
       "8741    They served us stale rice.  Average main dishe...\n",
       "3938    We were so disappointed!  We were on vacation ...\n",
       "7631    this is a business located in the fry's grocer...\n",
       "8681    As I promised myself, I'd go back again to try...\n",
       "1532    Cold, under done chips. If a Mexican food rest...\n",
       "113     Unless you are a regular or look like your wal...\n",
       "4165    OMG! what is the rave about? this place is dis...\n",
       "9299    The salad plates were not chilled... As they u...\n",
       "4311    Donuts are really good, if they have any when ...\n",
       "7035    Totally excited to try this place out, my gran...\n",
       "8000    Still a place that is unacceptable in my book-...\n",
       "3755    Have been going to LGO since 2003 and have alw...\n",
       "507     HELLISH HELLISH SUMMER WEATHER (March thru Oct...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print message text for the false positives\n",
    "X_test[y_test < y_pred_class]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus Exercise 9.6 (3 points)\n",
    "\n",
    "Let's see how well Naive Bayes performs when all reviews are included, rather than just 1-star and 5-star reviews:\n",
    "\n",
    "- Define X and y using the original DataFrame from step 1. (y should contain 5 different classes.)\n",
    "- Split the data into training and testing sets.\n",
    "- Calculate the testing accuracy of a Naive Bayes model.\n",
    "- Compare the testing accuracy with the null accuracy.\n",
    "- Print the confusion matrix.\n",
    "- Comment on the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
